import { config } from 'dotenv';

config({ path: '.env' });

const GLM_API_KEY = 'b4df6e149288463fb03903c94cc32ad1.gdjC4fj1TRyhSu19';

async function testGLMConnection() {
  console.log('ğŸ” æ¸¬è©¦ GLM 4.7 API é€£æ¥...\n');

  const options = {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${GLM_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'glm-4.7',
      messages: [
        { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚' },
        { role: 'user', content: 'è¯·ç°¡å–®ä»‹ç´¹ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„ç™¼å±•æ­·ç¨‹ã€‚' }
      ],
      temperature: 1,
      stream: false,
      thinking: {
        type: 'enabled',
        clear_thinking: true
      },
      do_sample: true,
      top_p: 0.95,
      tool_stream: false,
      response_format: { type: 'text' }
    })
  };

  try {
    console.log('ç™¼é€è«‹æ±‚åˆ°: https://open.bigmodel.cn/api/paas/v4/chat/completions\n');
    console.log('API Key:', GLM_API_KEY.substring(0, 20) + '...\n');

    const response = await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions', options);

    console.log('HTTP ç‹€æ…‹ç¢¼:', response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.log('éŒ¯èª¤è¨Šæ¯:', errorText);
      return;
    }

    const res = await response.json();
    console.log('\nâœ… API é€£æ¥æˆåŠŸï¼\n');
    console.log('å›æ‡‰å…§å®¹ï¼š');
    console.log(JSON.stringify(res, null, 2));

  } catch (err) {
    console.error('\nâŒ è«‹æ±‚å¤±æ•—:', err.message);
  }
}

testGLMConnection().then(() => {
  console.log('\nâœ¨ æ¸¬è©¦å®Œæˆ');
  process.exit(0);
});
